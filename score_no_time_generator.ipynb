{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time independent score based model\n",
    "Matt Sampson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- #\n",
    "# import libraries #\n",
    "# ---------------- #\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "from functools import partial\n",
    "from torchvision.models import ResNet\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------#\n",
    "#                     galaxy zoo dataset                      #\n",
    "#-------------------------------------------------------------#\n",
    "n = 3\n",
    "im_size = n * 32 \n",
    "batch_size = 128  # batch size for mini-batch gradient descent (stochastic grad desc.)\n",
    "transform  = T.Compose([\n",
    "        ToTensor(),\n",
    "        T.Resize(size=(im_size, im_size)),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #,\n",
    "        #T.Grayscale(num_output_channels=1)])\n",
    "file_name = '/Users/mattsampson/Documents/princeton_research/deblending_diffusion_Sampson_Melchior/datasets/galaxies/'\n",
    "dataset = datasets.ImageFolder(file_name,\n",
    "                        transform=transform)\n",
    "#-------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- #\n",
    "# Split data to training and validation #\n",
    "# ------------------------------------- #\n",
    "num_items = len(dataset)\n",
    "indices = list(range(num_items))\n",
    "random_state = np.random.get_state()\n",
    "np.random.seed(2019)\n",
    "np.random.shuffle(indices)\n",
    "np.random.set_state(random_state)\n",
    "train_indices, test_indices = indices[:int(num_items * 0.7)], indices[\n",
    "            int(num_items * 0.7):int(num_items * 0.8)]\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testing_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a U-net for the score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, bias=False):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=bias)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1, bias=False):\n",
    "    \"1x1 convolution\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                     padding=0, bias=bias)\n",
    "\n",
    "def dilated_conv3x3(in_planes, out_planes, dilation, bias=True):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, padding=dilation, dilation=dilation, bias=bias)\n",
    "\n",
    "\n",
    "class CondRCUBlock(nn.Module):\n",
    "    def __init__(self, features, n_blocks, n_stages, num_classes, normalizer, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            for j in range(n_stages):\n",
    "                setattr(self, '{}_{}_norm'.format(i + 1, j + 1), normalizer(features, num_classes, bias=True))\n",
    "                setattr(self, '{}_{}_conv'.format(i + 1, j + 1),\n",
    "                        conv3x3(features, features, stride=1, bias=False))\n",
    "\n",
    "        self.stride = 1\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_stages = n_stages\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        for i in range(self.n_blocks):\n",
    "            residual = x\n",
    "            for j in range(self.n_stages):\n",
    "                x = getattr(self, '{}_{}_norm'.format(i + 1, j + 1))(x, y)\n",
    "                x = self.act(x)\n",
    "                x = getattr(self, '{}_{}_conv'.format(i + 1, j + 1))(x)\n",
    "            x += residual\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondMSFBlock(nn.Module):\n",
    "    def __init__(self, in_planes, features, num_classes, normalizer):\n",
    "        \"\"\"\n",
    "        :param in_planes: tuples of input planes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert isinstance(in_planes, list) or isinstance(in_planes, tuple)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.features = features\n",
    "\n",
    "        for i in range(len(in_planes)):\n",
    "            self.convs.append(conv3x3(in_planes[i], features, stride=1, bias=True))\n",
    "            self.norms.append(normalizer(in_planes[i], num_classes, bias=True))\n",
    "\n",
    "    def forward(self, xs, y, shape):\n",
    "        sums = torch.zeros(xs[0].shape[0], self.features, *shape, device=xs[0].device)\n",
    "        for i in range(len(self.convs)):\n",
    "            h = self.norms[i](xs[i], y)\n",
    "            h = self.convs[i](h)\n",
    "            h = F.interpolate(h, size=shape, mode='bilinear', align_corners=True)\n",
    "            sums += h\n",
    "        return sums\n",
    "\n",
    "\n",
    "class CondRefineBlock(nn.Module):\n",
    "    def __init__(self, in_planes, features, num_classes, normalizer, act=nn.ReLU(), start=False, end=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert isinstance(in_planes, tuple) or isinstance(in_planes, list)\n",
    "        self.n_blocks = n_blocks = len(in_planes)\n",
    "\n",
    "        self.adapt_convs = nn.ModuleList()\n",
    "        for i in range(n_blocks):\n",
    "            self.adapt_convs.append(\n",
    "                CondRCUBlock(in_planes[i], 2, 2, num_classes, normalizer, act)\n",
    "            )\n",
    "\n",
    "        self.output_convs = CondRCUBlock(features, 3 if end else 1, 2, num_classes, normalizer, act)\n",
    "\n",
    "        if not start:\n",
    "            self.msf = CondMSFBlock(in_planes, features, num_classes, normalizer)\n",
    "\n",
    "        self.crp = CondCRPBlock(features, 2, num_classes, normalizer, act)\n",
    "\n",
    "    def forward(self, xs, y, output_shape):\n",
    "        assert isinstance(xs, tuple) or isinstance(xs, list)\n",
    "        hs = []\n",
    "        for i in range(len(xs)):\n",
    "            h = self.adapt_convs[i](xs[i], y)\n",
    "            hs.append(h)\n",
    "\n",
    "        if self.n_blocks > 1:\n",
    "            h = self.msf(hs, y, output_shape)\n",
    "        else:\n",
    "            h = hs[0]\n",
    "\n",
    "        h = self.crp(h, y)\n",
    "        h = self.output_convs(h, y)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class ConvMeanPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3, biases=True, adjust_padding=False):\n",
    "        super().__init__()\n",
    "        if not adjust_padding:\n",
    "            self.conv = nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "                nn.Conv2d(input_dim, output_dim, kernel_size, stride=1, padding=kernel_size // 2, bias=biases)\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv(inputs)\n",
    "        output = sum(\n",
    "            [output[:, :, ::2, ::2], output[:, :, 1::2, ::2], output[:, :, ::2, 1::2], output[:, :, 1::2, 1::2]]) / 4.\n",
    "        return output\n",
    "\n",
    "    \n",
    "class CRPBlock(nn.Module):\n",
    "    def __init__(self, features, n_stages, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(n_stages):\n",
    "            self.convs.append(conv3x3(features, features, stride=1, bias=False))\n",
    "        self.n_stages = n_stages\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(x)\n",
    "        path = x\n",
    "        for i in range(self.n_stages):\n",
    "            path = self.maxpool(path)\n",
    "            path = self.convs[i](path)\n",
    "            x = path + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class CondCRPBlock(nn.Module):\n",
    "    def __init__(self, features, n_stages, num_classes, normalizer, act=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        for i in range(n_stages):\n",
    "            self.norms.append(normalizer(features, num_classes, bias=True))\n",
    "            self.convs.append(conv3x3(features, features, stride=1, bias=False))\n",
    "        self.n_stages = n_stages\n",
    "        self.maxpool = nn.AvgPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.act(x)\n",
    "        path = x\n",
    "        for i in range(self.n_stages):\n",
    "            path = self.norms[i](path, y)\n",
    "            path = self.maxpool(path)\n",
    "            path = self.convs[i](path)\n",
    "            x = path + x\n",
    "        return x\n",
    "\n",
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, bias=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bias = bias\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        if self.bias:\n",
    "            self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "            self.embed.weight.data[:, :num_features].uniform_()  # Initialise scale at N(1, 0.02)\n",
    "            self.embed.weight.data[:, num_features:].zero_()  # Initialise bias at 0\n",
    "        else:\n",
    "            self.embed = nn.Embedding(num_classes, num_features)\n",
    "            self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.bn(x)\n",
    "        if self.bias:\n",
    "            gamma, beta = self.embed(y).chunk(2, dim=1)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "        else:\n",
    "            gamma = self.embed(y)\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * out\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ConditionalResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_classes, resample=None, act=nn.ELU(),\n",
    "                 normalization=ConditionalBatchNorm2d, adjust_padding=False, dilation=None):\n",
    "        super().__init__()\n",
    "        self.non_linearity = act\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.resample = resample\n",
    "        if resample == 'down':\n",
    "            if dilation is not None:\n",
    "                self.conv1 = dilated_conv3x3(input_dim, input_dim, dilation=dilation)\n",
    "                self.normalize2 = normalization(input_dim, num_classes)\n",
    "                self.conv2 = dilated_conv3x3(input_dim, output_dim, dilation=dilation)\n",
    "                conv_shortcut = partial(dilated_conv3x3, dilation=dilation)\n",
    "            else:\n",
    "                self.conv1 = nn.Conv2d(input_dim, input_dim, 3, stride=1, padding=1)\n",
    "                self.normalize2 = normalization(input_dim, num_classes)\n",
    "                self.conv2 = ConvMeanPool(input_dim, output_dim, 3, adjust_padding=adjust_padding)\n",
    "                conv_shortcut = partial(ConvMeanPool, kernel_size=1, adjust_padding=adjust_padding)\n",
    "\n",
    "        elif resample is None:\n",
    "            if dilation is not None:\n",
    "                conv_shortcut = partial(dilated_conv3x3, dilation=dilation)\n",
    "                self.conv1 = dilated_conv3x3(input_dim, output_dim, dilation=dilation)\n",
    "                self.normalize2 = normalization(output_dim, num_classes)\n",
    "                self.conv2 = dilated_conv3x3(output_dim, output_dim, dilation=dilation)\n",
    "            else:\n",
    "                conv_shortcut = nn.Conv2d\n",
    "                self.conv1 = nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
    "                self.normalize2 = normalization(output_dim, num_classes)\n",
    "                self.conv2 = nn.Conv2d(output_dim, output_dim, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            raise Exception('invalid resample value')\n",
    "\n",
    "        if output_dim != input_dim or resample is not None:\n",
    "            self.shortcut = conv_shortcut(input_dim, output_dim)\n",
    "\n",
    "        self.normalize1 = normalization(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        output = self.normalize1(x, y)\n",
    "        output = self.non_linearity(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.normalize2(output, y)\n",
    "        output = self.non_linearity(output)\n",
    "        output = self.conv2(output)\n",
    "\n",
    "        if self.output_dim == self.input_dim and self.resample is None:\n",
    "            shortcut = x\n",
    "        else:\n",
    "            shortcut = self.shortcut(x)\n",
    "\n",
    "        return shortcut + output\n",
    "\n",
    "\n",
    "class ConditionalInstanceNorm2dPlus(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, bias=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bias = bias\n",
    "        self.instance_norm = nn.InstanceNorm2d(num_features, affine=False, track_running_stats=False)\n",
    "        if bias:\n",
    "            self.embed = nn.Embedding(num_classes, num_features * 3)\n",
    "            self.embed.weight.data[:, :2 * num_features].normal_(1, 0.02)  # Initialise scale at N(1, 0.02)\n",
    "            self.embed.weight.data[:, 2 * num_features:].zero_()  # Initialise bias at 0\n",
    "        else:\n",
    "            self.embed = nn.Embedding(num_classes, 2 * num_features)\n",
    "            self.embed.weight.data.normal_(1, 0.02)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        means = torch.mean(x, dim=(2, 3))\n",
    "        m = torch.mean(means, dim=-1, keepdim=True)\n",
    "        v = torch.var(means, dim=-1, keepdim=True)\n",
    "        means = (means - m) / (torch.sqrt(v + 1e-5))\n",
    "        h = self.instance_norm(x)\n",
    "\n",
    "        if self.bias:\n",
    "            gamma, alpha, beta = self.embed(y).chunk(3, dim=-1)\n",
    "            h = h + means[..., None, None] * alpha[..., None, None]\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h + beta.view(-1, self.num_features, 1, 1)\n",
    "        else:\n",
    "            gamma, alpha = self.embed(y).chunk(2, dim=-1)\n",
    "            h = h + means[..., None, None] * alpha[..., None, None]\n",
    "            out = gamma.view(-1, self.num_features, 1, 1) * h\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CondRefineNetDilated(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logit_transform = False\n",
    "        # self.norm = ConditionalInstanceNorm2d\n",
    "        self.norm = ConditionalInstanceNorm2dPlus\n",
    "        self.ngf = ngf = 64\n",
    "        self.num_classes = 10\n",
    "        self.act = act = nn.ELU()\n",
    "        # self.act = act = nn.ReLU(True)\n",
    "        data_channels = 3\n",
    "        image_size = 28\n",
    "\n",
    "        self.begin_conv = nn.Conv2d(data_channels, ngf, 3, stride=1, padding=1)\n",
    "        self.normalizer = self.norm(ngf, self.num_classes)\n",
    "\n",
    "        self.end_conv = nn.Conv2d(ngf, data_channels, 3, stride=1, padding=1)\n",
    "\n",
    "        self.res1 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(self.ngf, self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm),\n",
    "            ConditionalResidualBlock(self.ngf, self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm)]\n",
    "        )\n",
    "\n",
    "        self.res2 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                     normalization=self.norm),\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm)]\n",
    "        )\n",
    "\n",
    "        self.res3 = nn.ModuleList([\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                     normalization=self.norm, dilation=2),\n",
    "            ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                     normalization=self.norm, dilation=2)]\n",
    "        )\n",
    "\n",
    "        if image_size == 28:\n",
    "            self.res4 = nn.ModuleList([\n",
    "                ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                         normalization=self.norm, adjust_padding=True, dilation=4),\n",
    "                ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                         normalization=self.norm, dilation=4)]\n",
    "            )\n",
    "        else:\n",
    "            self.res4 = nn.ModuleList([\n",
    "                ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample='down', act=act,\n",
    "                                         normalization=self.norm, adjust_padding=False, dilation=4),\n",
    "                ConditionalResidualBlock(2 * self.ngf, 2 * self.ngf, self.num_classes, resample=None, act=act,\n",
    "                                         normalization=self.norm, dilation=4)]\n",
    "            )\n",
    "\n",
    "        self.refine1 = CondRefineBlock([2 * self.ngf], 2 * self.ngf, self.num_classes, self.norm, act=act, start=True)\n",
    "        self.refine2 = CondRefineBlock([2 * self.ngf, 2 * self.ngf], 2 * self.ngf, self.num_classes, self.norm, act=act)\n",
    "        self.refine3 = CondRefineBlock([2 * self.ngf, 2 * self.ngf], self.ngf, self.num_classes, self.norm, act=act)\n",
    "        self.refine4 = CondRefineBlock([self.ngf, self.ngf], self.ngf, self.num_classes, self.norm, act=act, end=True)\n",
    "\n",
    "    def _compute_cond_module(self, module, x, y):\n",
    "        for m in module:\n",
    "            x = m(x, y)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if not self.logit_transform:\n",
    "            x = 2 * x - 1.\n",
    "\n",
    "        output = self.begin_conv(x)\n",
    "\n",
    "        layer1 = self._compute_cond_module(self.res1, output, y)\n",
    "        layer2 = self._compute_cond_module(self.res2, layer1, y)\n",
    "        layer3 = self._compute_cond_module(self.res3, layer2, y)\n",
    "        layer4 = self._compute_cond_module(self.res4, layer3, y)\n",
    "\n",
    "        ref1 = self.refine1([layer4], y, layer4.shape[2:])\n",
    "        ref2 = self.refine2([layer3, ref1], y, layer3.shape[2:])\n",
    "        ref3 = self.refine3([layer2, ref2], y, layer2.shape[2:])\n",
    "        output = self.refine4([layer1, ref3], y, layer1.shape[2:])\n",
    "\n",
    "        output = self.normalizer(output, y)\n",
    "        output = self.act(output)\n",
    "        output = self.end_conv(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- #\n",
    "# loss function #\n",
    "# ------------- #\n",
    "def anneal_dsm_score_estimation(scorenet, samples, labels, sigmas, anneal_power=2.):\n",
    "    used_sigmas = sigmas[labels].view(samples.shape[0], *([1] * len(samples.shape[1:])))\n",
    "    perturbed_samples = samples + torch.randn_like(samples) * used_sigmas\n",
    "    target = - 1 / (used_sigmas ** 2) * (perturbed_samples - samples)\n",
    "    scores = scorenet(perturbed_samples, labels)\n",
    "    target = target.view(target.shape[0], -1)\n",
    "    scores = scores.view(scores.shape[0], -1)\n",
    "    loss = 1 / 2. * ((scores - target) ** 2).sum(dim=-1) * used_sigmas.squeeze() ** anneal_power\n",
    "\n",
    "    return loss.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\tCPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6cf5be461143e998993c1e3d43ddb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "total loss: inf:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------- #\n",
    "# define training routine # \n",
    "# ----------------------- #\n",
    "\n",
    "# grab the compute we have available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\t\" + (f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\"))\n",
    "\n",
    "# define training parameters\n",
    "n_epochs    = 6                     # number of training epochs\n",
    "lr          = 1e-4                   # learning rate\n",
    "train       = False                # train yes/no\n",
    "store_path  = 'score_anneal_96.pt'      # model save name\n",
    "n_steps     = 50000                  # cap total number of steps\n",
    "sigma_begin = 1                      # start of noise vector\n",
    "sigma_end   = 0.01                   # end of noise vector\n",
    "num_classes = 10                     # num elements in noise vector\n",
    "\n",
    "# define the model and attach to compute device\n",
    "score =  CondRefineNetDilated().to(device)\n",
    "score = torch.nn.DataParallel(score)\n",
    "\n",
    "# define the training optimiser\n",
    "optimizer = Adam(score.parameters(), lr=lr)\n",
    "sigmas    = torch.tensor(np.exp(np.linspace(np.log(sigma_begin), np.log(sigma_end),\n",
    "                               num_classes))).float().to(device)\n",
    "\n",
    "# run the training\n",
    "pbar = tqdm(range(n_epochs), desc='total loss: inf')\n",
    "\n",
    "if train:\n",
    "    best_loss = 1e20\n",
    "    step = 0\n",
    "    sigma = 0.01\n",
    "    for epoch in pbar:\n",
    "        avg_loss = 0.\n",
    "        for i, (X, y) in enumerate(loader):\n",
    "            step += 1\n",
    "            X = X.to(device)\n",
    "            X = X / 256. * 255. + torch.rand_like(X) / 256.\n",
    "            labels = torch.randint(0, len(sigmas), (X.shape[0],), device=X.device)\n",
    "            loss = anneal_dsm_score_estimation(score, X, labels, sigmas, 2)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item()\n",
    "            \n",
    "            if step >= n_steps:\n",
    "                    break\n",
    "        \n",
    "        if (avg_loss < best_loss):\n",
    "            torch.save(score.state_dict(), store_path)\n",
    "            pbar.set_description(\"best model saved - total loss: %d\" % avg_loss )\n",
    "            best_loss = avg_loss\n",
    "        else:\n",
    "            pbar.set_description(\"no save - total loss: %d\" % avg_loss )\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# Loading the trained model #\n",
    "# ------------------------- #\n",
    "score_test  = CondRefineNetDilated().to(device)\n",
    "score_test  = torch.nn.DataParallel(score_test)\n",
    "score_test.load_state_dict(torch.load(store_path, map_location=device))\n",
    "\n",
    "# ----------------------------------------------------- #\n",
    "# Here we define a routine for image sampling utalising # \n",
    "# Langevin dynamics (Langevin MCMC)                     #\n",
    "# ----------------------------------------------------- #\n",
    "\n",
    "def Langevin_dynamics(x_mod, scorenet, n_steps=200, step_lr=0.00005, L=10):\n",
    "        images = []\n",
    "        sigma  = np.linspace(1,1e-2,L)\n",
    "\n",
    "        with torch.no_grad():\n",
    "        #for i in range(L):\n",
    "            for _ in range(n_steps):\n",
    "                images.append(torch.clamp(x_mod, 0.0, 1.0).to('cpu'))\n",
    "                noise   = torch.randn_like(x_mod) * np.sqrt(step_lr * 2)\n",
    "                x_noisy = x_mod + noise\n",
    "                grad    = scorenet(x_mod)\n",
    "                x_mod   = x_mod - step_lr * grad + noise\n",
    "            x_mod = x_mod\n",
    "\n",
    "        return images\n",
    "    \n",
    "\n",
    "        \n",
    "def anneal_Langevin_dynamics(x_mod, scorenet, sigmas, n_steps_each=100, step_lr=0.00002,denoise=True):\n",
    "        images = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for c, sigma in tqdm(enumerate(sigmas), total=len(sigmas), desc='annealed Langevin dynamics sampling'):\n",
    "                labels = torch.ones(x_mod.shape[0], device=x_mod.device) * c\n",
    "                labels = labels.long()\n",
    "                step_size = step_lr * (sigma / sigmas[-1]) ** 2\n",
    "                step_size_cpu = step_size.to('cpu') # addition \n",
    "                for s in range(n_steps_each):\n",
    "                    images.append(torch.clamp(x_mod, 0.0, 1.0).to('cpu'))\n",
    "                    noise = torch.randn_like(x_mod) * np.sqrt(step_size_cpu * 2)\n",
    "                    grad = scorenet(x_mod, labels)\n",
    "                    x_mod = x_mod + step_size * grad + noise\n",
    "                \n",
    "                # add denoising step from Song improved +2020\n",
    "                if denoise:\n",
    "                    last_noise = (len(sigmas) - 1) * torch.ones(x_mod.shape[0], device=x_mod.device)\n",
    "                    last_noise = last_noise.long()\n",
    "                    x_mod = x_mod + sigmas[-1] ** 2 * scorenet(x_mod, last_noise)\n",
    "                    images.append(x_mod.to('cpu'))\n",
    "\n",
    "            return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35e45b8fdf467f81d94e8ad0f55a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "annealed Langevin dynamics sampling:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51112e3193124b55b0d72c1fbd284256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "saving images:   0%|          | 0/1010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------ #\n",
    "# Run sampling #\n",
    "# ------------ #\n",
    "grid_size       = 2\n",
    "data_channels   = 3\n",
    "image_size      = im_size\n",
    "logit_transform = False\n",
    "imgs            = []\n",
    "image_folder    = 'score_no_time/'\n",
    "n_steps         = 150\n",
    "\n",
    "\n",
    "score_test.eval()\n",
    "samples = torch.rand(grid_size ** 2, data_channels, image_size, image_size, device=device)\n",
    "all_samples = anneal_Langevin_dynamics(samples, score_test ,sigmas)\n",
    "\n",
    "for i, sample in enumerate(tqdm(all_samples, total=len(all_samples), desc='saving images')):\n",
    "                sample = sample.view(grid_size ** 2, data_channels, image_size,\n",
    "                                    image_size)\n",
    "\n",
    "                if logit_transform:\n",
    "                    sample = torch.sigmoid(sample)\n",
    "\n",
    "                image_grid = make_grid(sample, nrow=grid_size)\n",
    "                if i % 10 == 0:\n",
    "                    im = Image.fromarray(image_grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy())\n",
    "                    imgs.append(im)\n",
    "\n",
    "save_image(image_grid, os.path.join(image_folder, 'image_step__denoise_96_single{}.png'.format(n_steps)))\n",
    "torch.save(sample, os.path.join(image_folder, 'image_step_raw_{}.pth'.format(n_steps)))\n",
    "                \n",
    "imgs[0].save(os.path.join(image_folder, \"galaxy_no_time_denoise_96_single.gif\"), save_all=True, append_images=imgs[1:], duration=1, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bc68688a3ed8a5ce6018ce4ac9bdddfcbacccfa8757535ca0e210f8a40fad74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
